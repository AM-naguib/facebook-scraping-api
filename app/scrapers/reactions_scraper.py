"""
Facebook Reactions Scraper - API Version
Modified version of the original scraper for API usage
"""

import json
import re
import requests
import time
import urllib.parse
import base64
import gzip
import io
from datetime import datetime
from typing import Optional, Dict, List, Any


class FacebookReactionsScraper:
    """Ø³ÙƒØ±Ø¨Øª Ù…ØªÙ‚Ø¯Ù… Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù…Ù† ÙÙŠØ³Ø¨ÙˆÙƒ - Ù†Ø³Ø®Ø© API"""
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø³ÙƒØ±Ø¨Øª"""
        self.session = requests.Session()
        self.fb_dtsg = None
        self.lsd = None
        self.jazoest = "25729"
        self.user_id = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª headers Ù„Ù€ GraphQL API
        self.api_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'en-US,en;q=0.9,ar;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Content-Type': 'application/x-www-form-urlencoded',
            'Origin': 'https://www.facebook.com',
            'Referer': 'https://www.facebook.com/',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'x-fb-friendly-name': 'CometUFIReactionsDialogTabContentRefetchQuery',
            'priority': 'u=1, i'
        }
        
        # headers Ù„Ù„ØªØµÙØ­ Ø§Ù„Ø¹Ø§Ø¯ÙŠ - Ù…Ø¹ User-Agents Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„ØªÙˆØ§ÙÙ‚
        self.browser_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,ar;q=0.8',
            'Accept-Encoding': 'identity',  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ØºØ· Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ decoding
            'Cache-Control': 'max-age=0',
            'Connection': 'keep-alive',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1',
            'Pragma': 'no-cache'
        }
        
        # Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
        self.reaction_types = {
            '115940658764963': 'LIKE',
            '115940695431625': 'LOVE', 
            '115940658764959': 'HAHA',
            '115940658764965': 'WOW',
            '115940695431634': 'SORRY',
            '115940658764962': 'ANGRY',
            '478547315650144': 'CARE',
            '1635855486666999': 'SUPPORT'
        }
        
    def load_cookies_from_array(self, cookies_array: List[Dict]) -> bool:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ù…Ù† array - Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ API"""
        try:
            print(f"ğŸ” [DEBUG] Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²...")
            print(f"ğŸ” [DEBUG] Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø©: {len(cookies_array)}")
            
            facebook_cookies_count = 0
            for cookie in cookies_array:
                if cookie.get('domain') == '.facebook.com':
                    facebook_cookies_count += 1
                    print(f"ğŸ” [DEBUG] ØªØ­Ù…ÙŠÙ„ ÙƒÙˆÙƒÙŠ: {cookie['name']}")
                    
                    self.session.cookies.set(
                        cookie['name'], 
                        cookie['value'], 
                        domain=cookie['domain']
                    )
                    
                    if cookie['name'] == 'c_user':
                        self.user_id = cookie['value']
                        print(f"ğŸ” [DEBUG] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ user_id: {self.user_id}")
            
            print(f"ğŸ” [DEBUG] ØªÙ… ØªØ­Ù…ÙŠÙ„ {facebook_cookies_count} ÙƒÙˆÙƒÙŠ Ù…Ù† ÙÙŠØ³Ø¨ÙˆÙƒ")
            
            if not self.user_id:
                print(f"âŒ [DEBUG] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ c_user ÙÙŠ Ø§Ù„ÙƒÙˆÙƒÙŠØ²")
                return False
            
            print(f"âœ… [DEBUG] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø¨Ù†Ø¬Ø§Ø­")
            return True
            
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {e}")
            import traceback
            print(f"âŒ [DEBUG] ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£:")
            traceback.print_exc()
            return False
            
    def check_cookies_validity(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø¨Ø³Ø±Ø¹Ø©"""
        try:
            print(f"ğŸ” [DEBUG] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ²...")
            
            # Ø·Ù„Ø¨ Ø³Ø±ÙŠØ¹ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙˆÙƒÙŠØ²
            test_response = self.session.head('https://www.facebook.com/', timeout=10)
            print(f"ğŸ” [DEBUG] Ø­Ø§Ù„Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {test_response.status_code}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙˆÙƒÙŠØ² Ø£Ø³Ø§Ø³ÙŠØ©
            important_cookies = ['c_user', 'xs', 'datr']
            for cookie_name in important_cookies:
                if cookie_name in [cookie.name for cookie in self.session.cookies]:
                    print(f"âœ… [DEBUG] Ø§Ù„ÙƒÙˆÙƒÙŠ {cookie_name} Ù…ÙˆØ¬ÙˆØ¯")
                else:
                    print(f"âŒ [DEBUG] Ø§Ù„ÙƒÙˆÙƒÙŠ {cookie_name} Ù…ÙÙ‚ÙˆØ¯")
                    
            return test_response.status_code in [200, 302]
            
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {e}")
            return True  # Ù†ØªØ§Ø¨Ø¹ Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    
    def decompress_content(self, response) -> str:
        """Ø¥Ù„ØºØ§Ø¡ Ø¶ØºØ· Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±"""
        try:
            content_encoding = response.headers.get('content-encoding', '').lower()
            
            if content_encoding == 'gzip':
                print(f"ğŸ” [DEBUG] Ø¥Ù„ØºØ§Ø¡ Ø¶ØºØ· gzip ÙŠØ¯ÙˆÙŠØ§Ù‹...")
                return gzip.decompress(response.content).decode('utf-8')
            elif content_encoding == 'deflate':
                print(f"ğŸ” [DEBUG] Ø¥Ù„ØºØ§Ø¡ Ø¶ØºØ· deflate ÙŠØ¯ÙˆÙŠØ§Ù‹...")
                import zlib
                return zlib.decompress(response.content).decode('utf-8')
            else:
                # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…Ø¶ØºÙˆØ· Ø£Ùˆ requests ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡
                return response.text
                
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¶ØºØ·: {e}")
            # ÙƒØ¨Ø¯ÙŠÙ„ØŒ Ø¬Ø±Ø¨ response.text Ø§Ù„Ø¹Ø§Ø¯ÙŠ
            try:
                return response.text
            except:
                return response.content.decode('utf-8', errors='ignore')

    def extract_tokens(self) -> bool:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ù† ÙÙŠØ³Ø¨ÙˆÙƒ"""
        try:
            print(f"ğŸ” [DEBUG] Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²...")
            print(f"ğŸ” [DEBUG] Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ GET Ø¥Ù„Ù‰ https://www.facebook.com/")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£ÙˆÙ„Ù‰ Ù…Ø¹ User-Agent Ø§Ù„Ø­Ø§Ù„ÙŠ
            response = self.session.get('https://www.facebook.com/', 
                                      headers=self.browser_headers, timeout=30)
            
            # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ Ø¬Ø±Ø¨ user-agent Ø¢Ø®Ø±
            if response.status_code != 200:
                print(f"ğŸ” [DEBUG] Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙØ´Ù„Øª ({response.status_code})ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ User-Agent Ù…Ø®ØªÙ„Ù...")
                alternative_headers = self.browser_headers.copy()
                alternative_headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                response = self.session.get('https://www.facebook.com/', 
                                          headers=alternative_headers, timeout=30)
            
            print(f"ğŸ” [DEBUG] Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.status_code}")
            print(f"ğŸ” [DEBUG] Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø§Ù…: {len(response.content)} Ø¨Ø§ÙŠØª")
            print(f"ğŸ” [DEBUG] Content-Type: {response.headers.get('content-type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            print(f"ğŸ” [DEBUG] Content-Encoding: {response.headers.get('content-encoding', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            
            if response.status_code != 200:
                print(f"âŒ [DEBUG] ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù…Ø¹ Ø­Ø§Ù„Ø©: {response.status_code}")
                return False
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù„ØºØ§Ø¡ Ø¶ØºØ· Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØµØµØ©
            try:
                content = self.decompress_content(response)
                print(f"ğŸ” [DEBUG] Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¹Ø¯ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¶ØºØ·: {len(content)} Ø­Ø±Ù")
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù†Øµ ØµØ§Ù„Ø­
                if len(content) == 0:
                    print(f"âŒ [DEBUG] Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø±Øº")
                    return False
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ HTML tags Ø£Ø³Ø§Ø³ÙŠØ©
                if '<html' not in content.lower() and '<div' not in content.lower() and '<script' not in content.lower():
                    print(f"âŒ [DEBUG] Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ ÙƒÙ€ HTML ØµØ­ÙŠØ­")
                    print(f"ğŸ” [DEBUG] Ø£ÙˆÙ„ 200 Ø­Ø±Ù: {repr(content[:200])}")
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø¹ headers Ù…Ø®ØªÙ„ÙØ©
                    print(f"ğŸ” [DEBUG] Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ headers Ù…Ø¨Ø³Ø·Ø©...")
                    simple_headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.5',
                        'Accept-Encoding': 'identity',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1'
                    }
                    response = self.session.get('https://www.facebook.com/', 
                                              headers=simple_headers, timeout=30)
                    content = self.decompress_content(response)
                    print(f"ğŸ” [DEBUG] Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {len(content)} Ø­Ø±Ù")
                    
            except Exception as e:
                print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {e}")
                import traceback
                traceback.print_exc()
                return False
            
            # Ø­ÙØ¸ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© Ù„Ù„Ø¯ÙŠØ¨Ø§Ø¬Ù†Ø¬ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            try:
                with open('debug_facebook_page.html', 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"ğŸ” [DEBUG] ØªÙ… Ø­ÙØ¸ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© ÙÙŠ debug_facebook_page.html")
            except:
                pass
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø£ÙˆÙ„ 500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ø¯ÙŠØ¨Ø§Ø¬Ù†Ø¬
            print(f"ğŸ” [DEBUG] Ø£ÙˆÙ„ 500 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰:")
            print(f"{'='*50}")
            print(content[:500])
            print(f"{'='*50}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£ÙˆÙ„Ø§Ù‹
            content_lower = content.lower()
            
            if any(keyword in content_lower for keyword in ['login', 'sign in', 'ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„']):
                print(f"âŒ [DEBUG] ÙŠØ¨Ø¯Ùˆ Ø£Ù† ÙÙŠØ³Ø¨ÙˆÙƒ ÙŠØ·Ù„Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ - Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©")
                return False
            
            if any(keyword in content_lower for keyword in ['error', 'not found', '404', 'Ø®Ø·Ø£']):
                print(f"âŒ [DEBUG] ÙÙŠØ³Ø¨ÙˆÙƒ ÙŠØ¹Ø±Ø¶ ØµÙØ­Ø© Ø®Ø·Ø£")
                return False
            
            if 'checkpoint' in content_lower or 'security' in content_lower:
                print(f"âŒ [DEBUG] ÙÙŠØ³Ø¨ÙˆÙƒ ÙŠØ·Ù„Ø¨ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø£Ù…Ø§Ù† - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø¬Ø¯ÙŠØ¯")
                return False
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ fb_dtsg
            print(f"ğŸ” [DEBUG] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† fb_dtsg...")
            dtsg_patterns = [
                r'"DTSGInitialData",\[\],\{"token":"([^"]+)"',
                r'"dtsg":\{"token":"([^"]+)"',
                r'fb_dtsg":"([^"]+)"',
                r'DTSGInitialData.*?"token":"([^"]+)"',
                r'"fb_dtsg":"([^"]+)"',
                r'fb_dtsg["\']?\s*:\s*["\']([^"\']+)["\']',
                r'name="fb_dtsg"\s+value="([^"]+)"',
                r'fb_dtsg.*?value="([^"]+)"',
                r'"token":"([a-zA-Z0-9_-]{20,})"',
                # Ø£Ù†Ù…Ø§Ø· Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¶ØºÙˆØ·
                r'dtsg[^a-zA-Z0-9]+([a-zA-Z0-9_-]{20,})',
                r'token[^a-zA-Z0-9]+([a-zA-Z0-9_-]{20,})'
            ]
            
            for i, pattern in enumerate(dtsg_patterns):
                print(f"ğŸ” [DEBUG] ØªØ¬Ø±ÙŠØ¨ Ù†Ù…Ø· fb_dtsg #{i+1}: {pattern}")
                match = re.search(pattern, content)
                if match:
                    self.fb_dtsg = match.group(1)
                    print(f"âœ… [DEBUG] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ fb_dtsg: {self.fb_dtsg[:20]}...")
                    break
                else:
                    print(f"âŒ [DEBUG] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ fb_dtsg Ø¨Ø§Ù„Ù†Ù…Ø· #{i+1}")
            
            if not self.fb_dtsg:
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ fb_dtsg Ø¨Ø£ÙŠ Ù†Ù…Ø·")
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†ØµÙˆØµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ dtsg Ø£Ùˆ token
                print(f"ğŸ” [DEBUG] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†ØµÙˆØµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'dtsg':")
                dtsg_matches = re.findall(r'.{0,50}dtsg.{0,50}', content, re.IGNORECASE)
                for match in dtsg_matches[:5]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬
                    print(f"  - {match}")
                
                print(f"ğŸ” [DEBUG] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†ØµÙˆØµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'token':")
                token_matches = re.findall(r'.{0,30}token.{0,30}', content, re.IGNORECASE)
                for match in token_matches[:5]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬
                    print(f"  - {match}")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ lsd
            print(f"ğŸ” [DEBUG] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† lsd...")
            lsd_patterns = [
                r'"LSD",\[\],\{"token":"([^"]+)"',
                r'"token":"([^"]{20,})"',
                r'"lsd":"([^"]+)"',
                r'lsd["\']?\s*:\s*["\']([^"\']+)["\']',
                r'name="lsd"\s+value="([^"]+)"',
                r'lsd.*?value="([^"]+)"',
                r'"LSD".*?"token":"([^"]+)"',
                # Ø£Ù†Ù…Ø§Ø· Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¶ØºÙˆØ·
                r'lsd[^a-zA-Z0-9]+([a-zA-Z0-9_-]{15,})',
                r'LSD[^a-zA-Z0-9]+([a-zA-Z0-9_-]{15,})'
            ]
            
            for i, pattern in enumerate(lsd_patterns):
                print(f"ğŸ” [DEBUG] ØªØ¬Ø±ÙŠØ¨ Ù†Ù…Ø· lsd #{i+1}: {pattern}")
                match = re.search(pattern, content)
                if match:
                    self.lsd = match.group(1)
                    print(f"âœ… [DEBUG] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ lsd: {self.lsd[:20]}...")
                    break
                else:
                    print(f"âŒ [DEBUG] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ lsd Ø¨Ø§Ù„Ù†Ù…Ø· #{i+1}")
            
            if not self.lsd:
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ lsd Ø¨Ø£ÙŠ Ù†Ù…Ø·")
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†ØµÙˆØµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ LSD
                print(f"ğŸ” [DEBUG] Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ù†ØµÙˆØµ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'LSD':")
                lsd_matches = re.findall(r'.{0,50}LSD.{0,50}', content, re.IGNORECASE)
                for match in lsd_matches[:5]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬
                    print(f"  - {match}")
            
            result = bool(self.fb_dtsg)
            print(f"ğŸ” [DEBUG] Ù†ØªÙŠØ¬Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²: {result}")
            print(f"ğŸ” [DEBUG] fb_dtsg: {'Ù…ÙˆØ¬ÙˆØ¯' if self.fb_dtsg else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
            print(f"ğŸ” [DEBUG] lsd: {'Ù…ÙˆØ¬ÙˆØ¯' if self.lsd else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
            
            return result
            
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²: {e}")
            import traceback
            print(f"âŒ [DEBUG] ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£:")
            traceback.print_exc()
            return False
    
    def extract_tokens_alternative(self) -> bool:
        """Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù…Ù† ØµÙØ­Ø© Ù…Ø®ØªÙ„ÙØ©"""
        try:
            print(f"ğŸ” [DEBUG] Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù…Ù† Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø©...")
            
            # Ø¬Ø±Ø¨ ØµÙØ­Ø© mobile facebook
            mobile_headers = self.browser_headers.copy()
            mobile_headers['User-Agent'] = 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1'
            
            response = self.session.get('https://m.facebook.com/', 
                                      headers=mobile_headers, timeout=30)
            
            if response.status_code == 200:
                content = self.decompress_content(response)
                print(f"ğŸ” [DEBUG] Ø­Ø¬Ù… Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„: {len(content)} Ø­Ø±Ù")
                
                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„
                dtsg_patterns = [
                    r'name="fb_dtsg"\s+value="([^"]+)"',
                    r'fb_dtsg.*?value="([^"]+)"',
                    r'"dtsg":"([^"]+)"',
                    r'dtsg[^a-zA-Z0-9]+([a-zA-Z0-9_-]{20,})'
                ]
                
                for pattern in dtsg_patterns:
                    match = re.search(pattern, content)
                    if match:
                        self.fb_dtsg = match.group(1)
                        print(f"âœ… [DEBUG] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ fb_dtsg Ù…Ù† Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„: {self.fb_dtsg[:20]}...")
                        break
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† lsd
                lsd_patterns = [
                    r'name="lsd"\s+value="([^"]+)"',
                    r'lsd.*?value="([^"]+)"',
                    r'"lsd":"([^"]+)"'
                ]
                
                for pattern in lsd_patterns:
                    match = re.search(pattern, content)
                    if match:
                        self.lsd = match.group(1)
                        print(f"âœ… [DEBUG] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ lsd Ù…Ù† Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„: {self.lsd[:20]}...")
                        break
            
            return bool(self.fb_dtsg)
            
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø©: {e}")
            return False

    def extract_post_id_from_url(self, post_url: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        try:
            post_url = post_url.strip()
            parsed_url = urllib.parse.urlparse(post_url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† permalink
            if "permalink.php" in parsed_url.path and 'story_fbid' in query_params:
                return query_params['story_fbid'][0]
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† direct post
            post_match = re.search(r'/posts/([^/?]+)', parsed_url.path)
            if post_match:
                return post_match.group(1)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®Ø±Ù‰ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            if '/posts/' in post_url:
                parts = post_url.split('/posts/')
                if len(parts) > 1:
                    post_id = parts[1].split('?')[0].split('/')[0]
                    return post_id
            
            return None
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª: {e}")
            return None

    def create_feedback_target_id(self, post_id: str) -> str:
        """Create feedback target ID from post ID"""
        feedback_string = f"feedback:{post_id}"
        encoded = base64.b64encode(feedback_string.encode()).decode()
        return encoded

    def smart_feedback_id_extractor(self, post_id: str, post_url: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ feedback_id Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙÙ‚Ø·"""
        try:
            feedback_target_id = self.create_feedback_target_id(post_id)
            return feedback_target_id
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ feedback_id: {e}")
            return None

    def get_reactions(self, feedback_id: str, limit: int = 0, delay: float = 2.0) -> List[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø¨ÙˆØ³Øª"""
        try:
            all_reactions = []
            cursor = None
            page_count = 0
            
            while True:
                page_count += 1
                
                # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù„Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨
                if limit == 0:
                    count_per_request = 50
                else:
                    remaining = limit - len(all_reactions)
                    count_per_request = min(10, remaining)
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ variables Ù„Ù„Ø·Ù„Ø¨
                variables = {
                    "count": count_per_request,
                    "cursor": cursor,
                    "feedbackTargetID": feedback_id,
                    "reactionID": None,
                    "scale": 1,
                    "id": feedback_id
                }
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ payload
                payload = self.build_request_payload(variables, page_count)
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ headers
                headers = self.api_headers.copy()
                headers['x-fb-lsd'] = self.lsd
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
                response = self.session.post(
                    'https://www.facebook.com/api/graphql/',
                    data=payload,
                    headers=headers,
                    timeout=30
                )
                
                if response.status_code != 200:
                    break
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                reactions_data = self.process_response(response)
                if not reactions_data:
                    break
                
                new_reactions = reactions_data.get('reactions', [])
                all_reactions.extend(new_reactions)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØµÙØ­Ø§Øª Ø£Ø®Ø±Ù‰
                page_info = reactions_data.get('page_info', {})
                has_next_page = page_info.get('has_next_page', False)
                cursor = page_info.get('end_cursor')
                
                # Ø´Ø±ÙˆØ· Ø§Ù„ØªÙˆÙ‚Ù
                if not has_next_page or not cursor:
                    break
                
                if limit > 0 and len(all_reactions) >= limit:
                    break
                
                # ØªØ£Ø®ÙŠØ± Ù‚Ø¨Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„ØªØ§Ù„ÙŠ
                time.sleep(delay)
            
            # Ù‚Ø·Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù„Ù„Ø­Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø­Ø¯ Ù…Ø­Ø¯Ø¯)
            if limit > 0 and len(all_reactions) > limit:
                all_reactions = all_reactions[:limit]
            
            return all_reactions
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª: {e}")
            return []

    def build_request_payload(self, variables: Dict, page_count: int) -> Dict:
        """Ø¨Ù†Ø§Ø¡ payload Ù„Ù„Ø·Ù„Ø¨"""
        return {
            'av': self.user_id,
            '__aaid': '0',
            '__user': self.user_id,
            '__a': '1',
            '__req': f'{page_count:02x}',
            '__hs': '20326.HYP:comet_pkg.2.1...0',
            'dpr': '1',
            '__ccg': 'EXCELLENT',
            '__rev': '1026326043',
            '__s': 'deup5g:m4uo1p:p0pyqa',
            '__hsi': '7542830019330714267',
            '__comet_req': '15',
            'fb_dtsg': self.fb_dtsg,
            'jazoest': self.jazoest,
            'lsd': self.lsd,
            '__spin_r': '1026326043',
            '__spin_b': 'trunk',
            '__spin_t': str(int(time.time())),
            'fb_api_caller_class': 'RelayModern',
            'fb_api_req_friendly_name': 'CometUFIReactionsDialogTabContentRefetchQuery',
            'variables': json.dumps(variables),
            'server_timestamps': 'true',
            'doc_id': '31470716059194219'
        }

    def process_response(self, response) -> Optional[Dict]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© API"""
        try:
            response_text = response.text
            if response_text.startswith('for (;;);'):
                response_text = response_text[9:]
            
            data = json.loads(response_text)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
            if 'data' in data and 'node' in data['data']:
                node = data['data']['node']
                
                if 'reactors' in node and 'edges' in node['reactors']:
                    reactions = []
                    
                    for edge in node['reactors']['edges']:
                        reaction_info = {
                            'user': self.extract_user_info(edge),
                            'reaction_type': self.extract_reaction_type(edge),
                            'timestamp': self.extract_timestamp(edge)
                        }
                        reactions.append(reaction_info)
                    
                    page_info = node['reactors'].get('page_info', {})
                    
                    return {
                        'reactions': reactions,
                        'page_info': page_info
                    }
            
            return None
            
        except json.JSONDecodeError as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© JSON: {e}")
            return None
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {e}")
            return None

    def extract_user_info(self, edge: Dict) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            user_info = {
                'id': None,
                'name': None,
                'profile_url': None,
                'profile_picture': None
            }
            
            if 'node' in edge:
                user = edge['node']
                user_info['id'] = user.get('id')
                user_info['name'] = user.get('name')
                user_info['profile_url'] = user.get('url') or user.get('profile_url')
                
                if 'profile_picture' in user and user['profile_picture']:
                    user_info['profile_picture'] = user['profile_picture'].get('uri')
            
            return user_info
            
        except Exception:
            return {'id': None, 'name': None, 'profile_url': None, 'profile_picture': None}

    def extract_reaction_type(self, edge: Dict) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„"""
        try:
            if 'feedback_reaction_info' in edge:
                reaction_info = edge['feedback_reaction_info']
                reaction_id = reaction_info.get('id', '')
                return self.reaction_types.get(reaction_id, 'LIKE')
            
            return 'LIKE'
        except Exception:
            return 'UNKNOWN'

    def extract_timestamp(self, edge: Dict) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÙ‚Øª Ø§Ù„ØªÙØ§Ø¹Ù„"""
        try:
            return None
        except Exception:
            return None

    def scrape_reactions_api(self, post_url: str, cookies_array: List[Dict], 
                           limit: int = 0, delay: float = 2.0) -> Dict:
        """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª - Ù†Ø³Ø®Ø© API"""
        try:
            print(f"ğŸ” [DEBUG] Ø¨Ø¯Ø¡ Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù…Ù†: {post_url}")
            print(f"ğŸ” [DEBUG] Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª: limit={limit}, delay={delay}")
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²...")
            if not self.load_cookies_from_array(cookies_array):
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²")
                return {"error": "ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²", "reactions": []}
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ²
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 1.5: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ²...")
            self.check_cookies_validity()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²...")
            if not self.extract_tokens():
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù…Ù† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")
                print(f"ğŸ” [DEBUG] Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø©...")
                if not self.extract_tokens_alternative():
                    print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚")
                    return {"error": "ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²", "reactions": []}
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 3: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª...")
            post_id = self.extract_post_id_from_url(post_url)
            if not post_id:
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª")
                return {"error": "ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª", "reactions": []}
            print(f"âœ… [DEBUG] Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª: {post_id}")
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ feedback_id
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 4: Ø¥Ù†Ø´Ø§Ø¡ feedback_id...")
            feedback_id = self.smart_feedback_id_extractor(post_id, post_url)
            if not feedback_id:
                print(f"âŒ [DEBUG] ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ feedback_id")
                return {"error": "ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ feedback_id", "reactions": []}
            print(f"âœ… [DEBUG] feedback_id: {feedback_id[:50]}...")
            
            # Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
            print(f"ğŸ” [DEBUG] Ø®Ø·ÙˆØ© 5: Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª...")
            reactions = self.get_reactions(feedback_id, limit, delay)
            print(f"âœ… [DEBUG] ØªÙ… Ø¬Ù„Ø¨ {len(reactions)} ØªÙØ§Ø¹Ù„")
            
            # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª
            reaction_stats = {}
            for reaction in reactions:
                reaction_type = reaction.get('reaction_type', 'UNKNOWN')
                reaction_stats[reaction_type] = reaction_stats.get(reaction_type, 0) + 1
            
            print(f"âœ… [DEBUG] Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª: {reaction_stats}")
            
            result = {
                "success": True,
                "post_url": post_url,
                "post_id": post_id,
                "total_reactions": len(reactions),
                "reaction_stats": reaction_stats,
                "reactions": reactions,
                "scraped_at": datetime.now().isoformat()
            }
            
            print(f"âœ… [DEBUG] ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù† Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª")
            return result
            
        except Exception as e:
            print(f"âŒ [DEBUG] Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø³ÙƒØ±Ø¨Øª: {str(e)}")
            import traceback
            print(f"âŒ [DEBUG] ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£:")
            traceback.print_exc()
            return {"error": f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø³ÙƒØ±Ø¨Øª: {str(e)}", "reactions": []}


