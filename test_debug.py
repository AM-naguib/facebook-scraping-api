#!/usr/bin/env python3
"""
Ø³ÙƒØ±Ø¨Øª Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù„Ø¯ÙŠØ¨Ø§Ø¬Ù†Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±
"""

import json
import sys
import os
from datetime import datetime

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append('.')

from app.scrapers.reactions_scraper import FacebookReactionsScraper

def test_token_extraction():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙÙ‚Ø·"""
    print("="*60)
    print("ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²")
    print("="*60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ù…Ù† Ø§Ù„Ù…Ù„Ù
    try:
        with open('cookies.json', 'r', encoding='utf-8') as f:
            cookies_data = json.load(f)
        
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(cookies_data)} ÙƒÙˆÙƒÙŠ Ù…Ù† Ø§Ù„Ù…Ù„Ù")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {e}")
        return False
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
    scraper = FacebookReactionsScraper()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
    if not scraper.load_cookies_from_array(cookies_data):
        print("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²")
        return False
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ÙƒÙˆÙƒÙŠØ²
    scraper.check_cookies_validity()
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²
    result = scraper.extract_tokens()
    
    print("="*60)
    print(f"ğŸ” Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {'Ù†Ø¬Ø­' if result else 'ÙØ´Ù„'}")
    if result:
        print(f"âœ… fb_dtsg: {scraper.fb_dtsg}")
        print(f"âœ… lsd: {scraper.lsd}")
    print("="*60)
    
    return result

def test_full_scraping():
    """Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§Ù…Ù„ Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª"""
    print("="*60)
    print("ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª")
    print("="*60)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
    try:
        with open('cookies.json', 'r', encoding='utf-8') as f:
            cookies_data = json.load(f)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {e}")
        return False
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
    scraper = FacebookReactionsScraper()
    
    # Ø±Ø§Ø¨Ø· ØªØ¬Ø±ÙŠØ¨ÙŠ (Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ø®ØªØ¨Ø§Ø±Ù‡)
    test_post_url = input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨ÙˆØ³Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±: ").strip()
    if not test_post_url:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨ÙˆØ³Øª")
        return False
    
    # Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª (Ø­Ø¯ Ø£Ù‚ØµÙ‰ 10 Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
    result = scraper.scrape_reactions_api(
        post_url=test_post_url,
        cookies_array=cookies_data,
        limit=10,
        delay=1.0
    )
    
    print("="*60)
    print("ğŸ” Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    print("="*60)
    
    return not result.get("error")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print(f"ğŸ• Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙŠ: {datetime.now()}")
    print(f"ğŸ–¥ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: {os.name}")
    print(f"ğŸ Ø¥ØµØ¯Ø§Ø± Python: {sys.version}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙÙ‚Ø·
    token_test_result = test_token_extraction()
    
    if token_test_result:
        print("\nâœ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù†Ø¬Ø­! Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ØŸ")
        continue_test = input("Ø§ÙƒØªØ¨ 'y' Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø£Ùˆ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø± Ù„Ù„ØªÙˆÙ‚Ù: ").strip().lower()
        
        if continue_test == 'y':
            test_full_scraping()
    else:
        print("\nâŒ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙØ´Ù„. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ÙƒÙˆÙƒÙŠØ².")
    
    # ØªÙ†Ø¸ÙŠÙ Ù…Ù„Ù Ø§Ù„Ø¯ÙŠØ¨Ø§Ø¬Ù†Ø¬ Ø¥Ù† ÙˆØ¬Ø¯
    if os.path.exists('debug_facebook_page.html'):
        print("\nğŸ” ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù debug_facebook_page.html Ù„Ù„ÙØ­Øµ")
        print("ÙŠÙ…ÙƒÙ†Ùƒ ÙØªØ­ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø±Ø¤ÙŠØ© Ù…Ø­ØªÙˆÙ‰ ØµÙØ­Ø© ÙÙŠØ³Ø¨ÙˆÙƒ Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø©")

if __name__ == "__main__":
    main()
