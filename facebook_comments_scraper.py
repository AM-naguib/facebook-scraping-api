#!/usr/bin/env python3
"""
Facebook Comments Scraper - Optimized
======================================
Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª Ù…Ù† ÙÙŠØ³Ø¨ÙˆÙƒ
- ÙÙ‚Ø· author_id ÙÙŠ JSON Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
- ÙƒÙˆØ¯ Ù…Ø­Ø³Ù† ÙˆØ£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„
- ÙØ­Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
"""

import json
import re
import requests
import time
import urllib.parse
import base64
from datetime import datetime


class FacebookCommentsScraper:
    """ÙØ¦Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ø¬Ù„Ø¨ ÙƒÙˆÙ…Ù†ØªØ§Øª ÙÙŠØ³Ø¨ÙˆÙƒ"""
    
    def __init__(self, cookies_file="cookies.json"):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙØ¦Ø©"""
        self.session = requests.Session()
        self.cookies_file = cookies_file
        self.fb_dtsg = None
        self.lsd = None
        self.jazoest = "25515"
        self.user_id = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ timeout Ø§ÙØªØ±Ø§Ø¶ÙŠ
        self.session.timeout = 30
        
    def load_cookies(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ù…Ù† Ù…Ù„Ù JSON"""
        try:
            print("ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²...")
            
            with open(self.cookies_file, 'r', encoding='utf-8') as f:
                cookies_data = json.load(f)
            
            if not isinstance(cookies_data, list):
                print("âŒ ÙÙˆØ±Ù…Ø§Øª Ù…Ù„Ù Ø§Ù„ÙƒÙˆÙƒÙŠØ² ØºÙŠØ± ØµØ­ÙŠØ­")
                return False
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
            loaded_count = 0
            for cookie in cookies_data:
                if cookie.get('domain') == '.facebook.com':
                    self.session.cookies.set(
                        cookie['name'], 
                        cookie['value'], 
                        domain=cookie['domain']
                    )
                    loaded_count += 1
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
                    if cookie['name'] == 'c_user':
                        self.user_id = cookie['value']
            
            if loaded_count == 0:
                print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙˆÙƒÙŠØ² ÙÙŠØ³Ø¨ÙˆÙƒ ØµØ§Ù„Ø­Ø©")
                return False
                
            if not self.user_id:
                print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
                return False
                
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {loaded_count} ÙƒÙˆÙƒÙŠØ² - Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {self.user_id}")
            return True
            
        except FileNotFoundError:
            print(f"âŒ Ù…Ù„Ù Ø§Ù„ÙƒÙˆÙƒÙŠØ² ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {self.cookies_file}")
            return False
        except json.JSONDecodeError:
            print("âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙƒÙˆÙƒÙŠØ²")
            return False
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²: {e}")
            return False

    def extract_tokens(self):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù…Ù† ÙÙŠØ³Ø¨ÙˆÙƒ"""
        try:
            print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²...")
            
            response = self.session.get('https://www.facebook.com/', timeout=30)
            
            if response.status_code != 200:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ÙÙŠØ³Ø¨ÙˆÙƒ: {response.status_code}")
                return False
            
            content = response.text
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ fb_dtsg
            dtsg_patterns = [
                r'"DTSGInitialData",\[\],\{"token":"([^"]+)"',
                r'"dtsg":\{"token":"([^"]+)"',
                r'fb_dtsg":"([^"]+)"',
                r'DTSGInitialData.*?"token":"([^"]+)"'
            ]
            
            for pattern in dtsg_patterns:
                match = re.search(pattern, content)
                if match:
                    self.fb_dtsg = match.group(1)
                    break
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ lsd
            lsd_patterns = [
                r'"LSD",\[\],\{"token":"([^"]+)"',
                r'"token":"([^"]{20,})"'
            ]
            
            for pattern in lsd_patterns:
                match = re.search(pattern, content)
                if match:
                    self.lsd = match.group(1)
                    break
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            if not self.fb_dtsg:
                print("âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ fb_dtsg")
                return False
                
            print(f"âœ… fb_dtsg: {self.fb_dtsg[:30]}...")
            
            if self.lsd:
                print(f"âœ… lsd: {self.lsd}")
            else:
                print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ lsd - Ø³ÙŠØªÙ… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ†Ù‡")
                
            print(f"âœ… jazoest: {self.jazoest}")
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²: {e}")
            return False

    def extract_post_id(self, post_url):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
        try:
            print(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨ÙˆØ³Øª...")
            
            parsed_url = urllib.parse.urlparse(post_url.strip())
            query_params = urllib.parse.parse_qs(parsed_url.query)
            
            post_id = None
            
            # Ù…Ù† Ù†ÙˆØ¹ permalink
            if "permalink.php" in parsed_url.path and 'story_fbid' in query_params:
                post_id = query_params['story_fbid'][0]
            # Ù…Ù† Ù†ÙˆØ¹ direct post
            elif "/posts/" in parsed_url.path:
                post_match = re.search(r'/posts/([^/?]+)', parsed_url.path)
                if post_match:
                    post_id = post_match.group(1)
            
            if not post_id:
                print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª")
                return None
                
            print(f"âœ… Ù…Ø¹Ø±Ù Ø§Ù„Ø¨ÙˆØ³Øª: {post_id}")
            
            # ØªØ­ÙˆÙŠÙ„ pfbid Ø¥Ù„Ù‰ feedback format
            if post_id.startswith('pfbid'):
                try:
                    feedback_data = f"feedback:{post_id}"
                    graphql_id = base64.b64encode(feedback_data.encode()).decode()
                    print(f"âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ pfbid Ø¥Ù„Ù‰ feedback format")
                    return graphql_id
                except Exception as e:
                    print(f"âš ï¸ ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ pfbid: {e} - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„Ø£ØµÙ„ÙŠ")
                    return post_id
            
            return post_id
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·: {e}")
            return None

    def fetch_comments_page(self, post_id, cursor=None):
        """Ø¬Ù„Ø¨ ØµÙØ­Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª"""
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
            variables = {
                "commentsAfterCount": -1,
                "commentsAfterCursor": cursor,
                "commentsBeforeCount": None,
                "commentsBeforeCursor": None,
                "commentsIntentToken": "RANKED_FILTERED_INTENT_V1",
                "feedLocation": "POST_PERMALINK_DIALOG",
                "focusCommentID": None,
                "scale": 2,
                "useDefaultActor": False,
                "id": post_id,
                "__relay_internal__pv__IsWorkUserrelayprovider": False
            }
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨
            data = {
                "av": self.user_id,
                "__aaid": "0",
                "__user": self.user_id,
                "__a": "1",
                "__req": "3n",
                "__hs": "20325.HYP:comet_pkg.2.1...0",
                "dpr": "1",
                "__ccg": "EXCELLENT",
                "__rev": "1026303884",
                "__s": "43pu0c:crpsn8:ehpbtp",
                "__comet_req": "15",
                "fb_dtsg": self.fb_dtsg,
                "jazoest": self.jazoest,
                "lsd": self.lsd or "",
                "__spin_r": "1026303884",
                "__spin_b": "trunk",
                "__spin_t": str(int(time.time())),
                "fb_api_caller_class": "RelayModern",
                "server_timestamps": "true",
                "fb_api_req_friendly_name": "CommentsListComponentsPaginationQuery",
                "variables": json.dumps(variables),
                "doc_id": "24170828295923210"
            }
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ headers
            headers = {
                'Accept': '*/*',
                'Accept-Language': 'en-US,en;q=0.9,ar;q=0.8',
                'Content-Type': 'application/x-www-form-urlencoded',
                'Origin': 'https://www.facebook.com',
                'Referer': 'https://www.facebook.com/',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-origin',
            }
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
            response = self.session.post(
                'https://www.facebook.com/api/graphql/',
                data=data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code != 200:
                print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨: {response.status_code}")
                return None, None
            
            try:
                return self.parse_response(response.json())
            except json.JSONDecodeError:
                print("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON")
                return None, None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª: {e}")
            return None, None

    def parse_response(self, response_data):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª"""
        try:
            # Ø§Ù„ØªÙ†Ù‚Ù„ ÙÙŠ Ø¨Ù†ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data = response_data.get('data', {})
            node = data.get('node')
            
            if not node:
                print("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©")
                return [], None
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª
            comment_rendering = node.get('comment_rendering_instance_for_feed_location', {})
            comments_data = comment_rendering.get('comments', {})
            
            if not comments_data:
                print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙˆÙ…Ù†ØªØ§Øª")
                return [], None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ pagination
            page_info = comments_data.get('page_info', {})
            next_cursor = None
            if page_info.get('has_next_page'):
                next_cursor = page_info.get('end_cursor')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª
            edges = comments_data.get('edges', [])
            comments = []
            
            for edge in edges:
                comment_node = edge.get('node', {})
                comment = self.extract_comment_data(comment_node)
                if comment:
                    comments.append(comment)
            
            return comments, next_cursor
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {e}")
            return [], None

    def extract_comment_data(self, comment_node):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙˆÙ…Ù†Øª - Ù…Ø­Ø³Ù† Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ author_id ÙÙ‚Ø·"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ author_id ÙÙ‚Ø· ÙƒÙ…Ø§ Ø·Ù„Ø¨Øª
            author = comment_node.get('author', {})
            author_id = author.get('id', '')
            
            if not author_id:
                return None  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª Ø¨Ø¯ÙˆÙ† author_id
            
            # Ø§Ù„Ù†Øµ
            body = comment_node.get('body', {})
            text = body.get('text', '') if body else ''
            
            # Ø§Ù„ØªØ§Ø±ÙŠØ®
            created_time = comment_node.get('created_time', 0)
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø· (Ù„Ù† ØªØ­ÙØ¸ ÙÙŠ JSON)
            author_name = author.get('name', 'Unknown')
            
            return {
                'author_id': author_id,  # ÙÙ‚Ø· author_id ÙÙŠ JSON
                'text': text,
                'created_time': created_time,
                # Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·
                '_display_name': author_name,  # Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·
                '_formatted_time': self.format_timestamp(created_time)  # Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·
            }
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙˆÙ…Ù†Øª: {e}")
            return None
    
    def format_timestamp(self, timestamp):
        """ØªØ­ÙˆÙŠÙ„ timestamp Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©"""
        try:
            if timestamp:
                dt = datetime.fromtimestamp(timestamp)
                return dt.strftime('%Y-%m-%d %H:%M:%S')
        except:
            pass
        return 'Unknown'

    def scrape_all_comments(self, post_url, delay=10, max_pages=None):
        """Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø©"""
        print("=" * 70)
        print("ğŸ” Facebook Comments Scraper - Optimized")
        print("=" * 70)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
        if not self.load_cookies():
            return None
            
        if not self.extract_tokens():
            return None
            
        post_id = self.extract_post_id(post_url)
        if not post_id:
            return None
        
        # Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª
        all_comments = []
        cursor = None
        page_count = 0
        
        print(f"\nğŸ’¬ Ø¨Ø¯Ø¡ Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª...")
        
        while True:
            page_count += 1
            
            if max_pages and page_count > max_pages:
                print(f"ğŸ›‘ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰: {max_pages} ØµÙØ­Ø©")
                break
            
            print(f"ğŸ“„ ØµÙØ­Ø© {page_count}...", end=" ")
            
            comments, next_cursor = self.fetch_comments_page(post_id, cursor)
            
            if not comments:
                print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙˆÙ…Ù†ØªØ§Øª")
                break
            
            print(f"âœ… {len(comments)} ÙƒÙˆÙ…Ù†Øª")
            all_comments.extend(comments)
            
            if not next_cursor:
                print("ğŸ“„ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
                break
            
            cursor = next_cursor
            
            # ÙØ§Ø±Ù‚ Ø²Ù…Ù†ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª
            if next_cursor:
                print(f"â³ Ø§Ù†ØªØ¸Ø§Ø± {delay} Ø«Ø§Ù†ÙŠØ©...")
                time.sleep(delay)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        result = {
            'post_url': post_url,
            'total_comments': len(all_comments),
            'pages_scraped': page_count,
            'scraped_at': datetime.now().isoformat(),
            'comments': []
        }
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª Ù„Ù„Ø­ÙØ¸ - ÙÙ‚Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        for comment in all_comments:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø¹Ø±Ø¶
            clean_comment = {
                'author_id': comment['author_id'],
                'text': comment['text'],
                'created_time': comment['created_time']
            }
            result['comments'].append(clean_comment)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ø®Øµ
        self.display_summary(result, all_comments)
        
        return result

    def display_summary(self, result, all_comments_with_display):
        """Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        print(f"\n" + "=" * 70)
        print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        print("=" * 70)
        
        print(f"ğŸ’¬ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª: {result['total_comments']}")
        print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {result['pages_scraped']}")
        print(f"ğŸ• ÙˆÙ‚Øª Ø§Ù„Ø¬Ù„Ø¨: {result['scraped_at']}")
        
        if all_comments_with_display:
            print(f"\nğŸ’¬ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª:")
            print("-" * 50)
            
            for i, comment in enumerate(all_comments_with_display[:5]):
                print(f"{i+1}. {comment.get('_display_name', 'Unknown')}")
                print(f"   ğŸ†” author_id: {comment['author_id']}")
                print(f"   ğŸ“… {comment.get('_formatted_time', 'Unknown')}")
                text = comment['text'][:80]
                if len(comment['text']) > 80:
                    text += "..."
                print(f"   ğŸ’­ {text}")
                print()
            
            if len(all_comments_with_display) > 5:
                print(f"... Ùˆ {len(all_comments_with_display) - 5} ÙƒÙˆÙ…Ù†Øª Ø¢Ø®Ø±")
        
        print("=" * 70)

    def save_results(self, results, filename=None):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù JSON"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"facebook_comments_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")
            return None


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    # Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨ÙˆØ³Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    test_url = "https://www.facebook.com/bantalrb.heba/posts/pfbid029Ra2EaMcbGn5miZxq5DHx2cS3NYiYGav7TBMzFWQ8JQ8fvs3T1BGpVKnR4sN44LVl"
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙƒØ´Ø·Ø© Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª
    scraper = FacebookCommentsScraper()
    
    # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª
    results = scraper.scrape_all_comments(
        post_url=test_url,
        delay=10,  # 10 Ø«ÙˆØ§Ù†Ù Ø¨ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        max_pages=None  # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª
    )
    
    if results:
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        scraper.save_results(results)
        print(f"\nğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“Š ØªÙ… Ø¬Ù„Ø¨ {results['total_comments']} ÙƒÙˆÙ…Ù†Øª Ù…Ù† {results['pages_scraped']} ØµÙØ­Ø©")
    else:
        print("âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙƒÙˆÙ…Ù†ØªØ§Øª")


if __name__ == "__main__":
    main()