#!/usr/bin/env python3
"""
Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙŠØ¯ÙˆÙŠ Ù„Ù€ feedback_id Ù…Ù† Ø£ÙŠ Ø¨ÙˆØ³Øª ÙÙŠØ³Ø¨ÙˆÙƒ
"""

import requests
import json
import re
from facebook_reactions_final import FacebookReactionsScraper

def extract_feedback_manually(post_url):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ feedback_id ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù…Ù† Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨ÙˆØ³Øª"""
    
    print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ feedback_id ÙŠØ¯ÙˆÙŠØ§Ù‹...")
    print(f"ğŸ“ Ø§Ù„Ø±Ø§Ø¨Ø·: {post_url}")
    
    scraper = FacebookReactionsScraper()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ²
    if not scraper.load_cookies():
        return None
    
    try:
        # Ø²ÙŠØ§Ø±Ø© Ø§Ù„ØµÙØ­Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        response = scraper.session.get(post_url, headers=scraper.browser_headers, timeout=30)
        
        if response.status_code == 200:
            content = response.text
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© - Ø§Ù„Ø­Ø¬Ù…: {len(content)} Ø­Ø±Ù")
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ù„ÙØ­Øµ
            with open("page_content_debug.html", "w", encoding="utf-8") as f:
                f.write(content)
            print("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© ÙÙŠ page_content_debug.html")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†Ù…Ø§Ø· feedback Ù…Ù…ÙƒÙ†Ø©
            patterns = [
                r'"feedback_id":"([^"]+)"',
                r'"feedbackTargetID":"([^"]+)"',
                r'"feedbackID":"([^"]+)"',
                r'"target_id":"([^"]+)"',
                r'feedback:(\d+)',
                r'"id":"(feedback:\d+)"',
                r'"feedback"[^}]*"id"[^"]*"([^"]+)"',
                r'ZmVlZGJhY2s[A-Za-z0-9+/=]+',
                r'"ufi_target_id":"([^"]+)"',
                r'"content_id":"([^"]+)"',
                r'"object_id":"([^"]+)"',
                r'"story_id":"([^"]+)"',
                r'"post_id":"([^"]+)"'
            ]
            
            found_ids = []
            
            print(f"\nğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† feedback patterns...")
            for i, pattern in enumerate(patterns, 1):
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    print(f"âœ… Pattern {i}: ÙˆØ¬Ø¯ {len(matches)} Ù…Ø·Ø§Ø¨Ù‚Ø©")
                    for match in matches[:3]:  # Ø£ÙˆÙ„ 3 Ù…Ø·Ø§Ø¨Ù‚Ø§Øª
                        print(f"   {match}")
                        if match not in found_ids:
                            found_ids.append(match)
                else:
                    print(f"âŒ Pattern {i}: Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª")
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            print(f"\nğŸ“‹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ({len(found_ids)}):")
            for i, fid in enumerate(found_ids, 1):
                print(f"{i:2d}. {fid}")
            
            return found_ids
            
        else:
            print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
        return None

def test_feedback_id(feedback_id, limit=5):
    """Ø§Ø®ØªØ¨Ø§Ø± feedback_id Ù„ÙŠØ±Ù‰ Ù‡Ù„ ÙŠØ¹Ø·ÙŠ Ù†ØªØ§Ø¦Ø¬"""
    
    print(f"\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± feedback_id: {feedback_id}")
    
    scraper = FacebookReactionsScraper()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙˆÙƒÙŠØ² ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆÙƒÙ†Ø²
    if not scraper.load_cookies() or not scraper.extract_tokens():
        return False
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ØªÙØ§Ø¹Ù„Ø§Øª
        variables = {
            "count": limit,
            "cursor": None,
            "feedbackTargetID": feedback_id,
            "reactionID": None,
            "scale": 1,
            "id": feedback_id
        }
        
        payload = scraper.build_request_payload(variables, 1)
        headers = scraper.api_headers.copy()
        headers['x-fb-lsd'] = scraper.lsd
        
        response = scraper.session.post(
            'https://www.facebook.com/api/graphql/',
            data=payload,
            headers=headers,
            timeout=30
        )
        
        if response.status_code == 200:
            reactions_data = scraper.process_response(response)
            if reactions_data and reactions_data.get('reactions'):
                reactions_count = len(reactions_data['reactions'])
                print(f"âœ… Ù†Ø¬Ø­! ÙˆØ¬Ø¯ {reactions_count} ØªÙØ§Ø¹Ù„")
                return True
            else:
                print(f"âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§Ø¹Ù„Ø§Øª")
                return False
        else:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø·Ù„Ø¨: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}")
        return False

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    # Ø±Ø§Ø¨Ø· Ø¨ÙˆØ³Øª Ù…Ø¹ Ø§Ù„Ø°Ù‡Ø¨
    post_url = "https://www.facebook.com/maa.althahab.sy/posts/pfbid027aesuQ7MZCiDFthVZ9nuEpz2RdapbkG88zm2SGCzyj5xBYsHYz5RL5GJFWkwxCjSl"
    
    print("=" * 80)
    print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ feedback_id ÙŠØ¯ÙˆÙŠØ§Ù‹")
    print("=" * 80)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
    found_ids = extract_feedback_manually(post_url)
    
    if found_ids:
        print(f"\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª...")
        
        for i, fid in enumerate(found_ids, 1):
            print(f"\n--- Ø§Ø®ØªØ¨Ø§Ø± {i}/{len(found_ids)} ---")
            if test_feedback_id(fid):
                print(f"ğŸ‰ Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ùˆ: {fid}")
                print(f"ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø¹ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ")
                break
        else:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ø±Ù ÙŠØ¹Ù…Ù„")
    else:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø¹Ø±ÙØ§Øª")

if __name__ == "__main__":
    main()

